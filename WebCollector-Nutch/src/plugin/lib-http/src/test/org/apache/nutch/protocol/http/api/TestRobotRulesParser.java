/**
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.nutch.protocol.http.api;

import org.junit.Assert;
import org.junit.Test;

import crawlercommons.robots.BaseRobotRules;

/**
 * JUnit test case which tests
 * 1. that robots filtering is performed correctly as per the agent name
 * 2. that crawl delay is extracted correctly from the robots file
 *
 */
public class TestRobotRulesParser {

  private static final String CONTENT_TYPE = "text/plain";
  private static final String SINGLE_AGENT = "Agent1";
  private static final String MULTIPLE_AGENTS = "Agent2, Agent1";
  private static final String UNKNOWN_AGENT = "AgentABC";
  private static final String CR = "\r";

  private static final String ROBOTS_STRING = 
      "User-Agent: Agent1 #foo" + CR 
      + "Disallow: /a" + CR 
      + "Disallow: /b/a" + CR 
      + "#Disallow: /c" + CR 
      + "Crawl-delay: 10" + CR  // set crawl delay for Agent1 as 10 sec
      + "" + CR 
      + "" + CR 
      + "User-Agent: Agent2" + CR 
      + "Disallow: /a/bloh" + CR 
      + "Disallow: /c" + CR
      + "Disallow: /foo" + CR
      + "Crawl-delay: 20" + CR
      + "" + CR 
      + "User-Agent: *" + CR 
      + "Disallow: /foo/bar/" + CR;   // no crawl delay for other agents

  private static final String[] TEST_PATHS = new String[] {
    "http://example.com/a",
    "http://example.com/a/bloh/foo.html",
    "http://example.com/b",
    "http://example.com/c",
    "http://example.com/b/a/index.html",
    "http://example.com/foo/bar/baz.html"
  };

  private static final boolean[] RESULTS = new boolean[] {
    false,  //  /a
    false,  //  /a/bloh/foo.html
    true,   //  /b
    true,   //  /c
    false,  //  /b/a/index.html
    true    //  /foo/bar/baz.html
  };

  private HttpRobotRulesParser parser;
  private BaseRobotRules rules;

  public TestRobotRulesParser() {
    parser = new HttpRobotRulesParser();
  }

  /**
   * Test that the robots rules are interpreted correctly by the robots rules parser. 
   */
  @Test
  public void testRobotsAgent() {
    rules = parser.parseRules("testRobotsAgent", ROBOTS_STRING.getBytes(), CONTENT_TYPE, SINGLE_AGENT);

    for(int counter = 0; counter < TEST_PATHS.length; counter++) {
      Assert.assertTrue("testing on agent (" + SINGLE_AGENT + "), and " 
          + "path " + TEST_PATHS[counter] 
              + " got " + rules.isAllowed(TEST_PATHS[counter]),
              rules.isAllowed(TEST_PATHS[counter]) == RESULTS[counter]);
    }

    rules = parser.parseRules("testRobotsAgent", ROBOTS_STRING.getBytes(), CONTENT_TYPE, MULTIPLE_AGENTS);

    for(int counter = 0; counter < TEST_PATHS.length; counter++) {
      Assert.assertTrue("testing on agents (" + MULTIPLE_AGENTS + "), and " 
          + "path " + TEST_PATHS[counter] 
              + " got " + rules.isAllowed(TEST_PATHS[counter]),
              rules.isAllowed(TEST_PATHS[counter]) == RESULTS[counter]);
    }
  }

  /**
   * Test that the crawl delay is extracted from the robots file for respective agent. 
   * If its not specified for a given agent, default value must be returned.
   */
  @Test
  public void testCrawlDelay() {
    // for SINGLE_AGENT, the crawl delay of 10 sec ie. 10000 msec must be returned by the parser
    rules = parser.parseRules("testCrawlDelay", ROBOTS_STRING.getBytes(), CONTENT_TYPE, SINGLE_AGENT);
    Assert.assertTrue("testing crawl delay for agent "+ SINGLE_AGENT +" : ", (rules.getCrawlDelay() == 10000));

    // for UNKNOWN_AGENT, the default crawl delay must be returned.
    rules = parser.parseRules("testCrawlDelay", ROBOTS_STRING.getBytes(), CONTENT_TYPE, UNKNOWN_AGENT);
    Assert.assertTrue("testing crawl delay for agent "+ UNKNOWN_AGENT +" : ", (rules.getCrawlDelay() == Long.MIN_VALUE));
  }
}
